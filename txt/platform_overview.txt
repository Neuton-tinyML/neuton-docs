Platform Overview: The Neuton platform enables users to solve machine learning tasks in various domains. This is made possible by processing sensor data (gyroscopes, accelerometers, magnetometers, electromyography, etc).

The Neuton platform accepts data in CSV format. A typical dataset contains independent features usually referred to as “predictors” and dependent variables which the model is learning to predict, referred to as “target” (label) or target variable. Each row of data represents the feature values. The first row in the table is used for column names. The data can be both fully prepared or raw sensor data.

For signal processing, the platform offers a wide range of options, including Feature Extraction and Feature Selection mechanisms.

To build the most compact models with high inference speed and optimal accuracy, users can control the model complexity settings. Model accuracy is calculated automatically on the split portion of the training dataset. Additionally, users can upload an independent dataset so that validation and calculation of metrics can be performed on holdout data.

During training, the model is looking for patterns and dependencies between the predictors and the target variable.

After the model has been trained, the user can download an Acrichve with a ready-to-use C Library and a calculation of a total footprint of the entire ML solution. The user is free to embed the C Library in the device or evaluate the model's quality on test data using the Inference Runner CLI tool, which is located in the Artifacts folder of the same downloadable archive.

The full machine learning workflow and pipeline within Neuton consist of 3 simple steps:
1. Select data for training
2. Train your model
3. Run inference on a device

Platform limitations: For tariff plan Zero Gravity, there are limitations of predict on the inference runner. 

Solution Creation: The model creation process within Neuton begins with creating a new Solution. The solution is the object for training parameters specification, results, and analysis processes management. After you have worked with Neuton and created some solutions, you can view and manage your solutions in the "My Solutions" workspace. To create a new solution with a list of previously created solutions click "Add New Solution". The "New Solution" pop-up window will appear. Add the desired "Solution Name" in Latin letters. After that, click "Next" to go to dataset import/selection.

FIM (Feature Importance Matrix): After the model has been trained, the platform displays a chart with the 10 features that had the most significant impact on the model prediction of the target variable (for the selected model). The chart can be found in the Results tab. The Feature Importance Matrix helps to evaluate the impact of features on the model. If the feature does not affect the model at all (normalized value = 0), then you can exclude this variable from building the model.

Preloaded Datasets: The Neuton platform offers a collection of preloaded datasets for various domains. You can use preloaded datasets to explore the capabilities of the platform without collecting data yourself. All settings are set by default, without the possibility of changing them. To train a model with preloaded datasets, you need to create a new solution and select the "Preload Datasets" tab when choosing a training dataset. Descriptions for the preloaded datasets can be found by clicking on the question mark.

Solutions Management: All solutions are described in the "My Solutions" list in a user’s workspace sorted by creation date in descending order (with the newest first). A user can change the sorting order by clicking the row near "Sort by created". In the Solution's information area the following information is displayed: Solution_ID - This is a unique solution number that will also be displayed in the C Library. Created - date and time when a solution was created. Task type - problem type for which solution was configured (Regression, Binary Classification, Multiclass Classification, Anomaly Detection). Digital Signal Processing - shows whether the Digital Signal Processing option for this solution was enabled or not. Data Type - selected input data type. Model Bit Depth - selected model bit depth and its value. Target metric - selected target metric for the model and its value. Solution status - (next to the solution name) reflects the current solution state.

To rename a solution, click the gear icon on the solution you would like to rename, then click "Rename".

To delete a Solution - click the gear icon associated with the solution that should be deleted, then click "Delete". The platform will ask to confirm if the solution and all associated data in "Dataset Storage" are to be permanently deleted. Once confirmed, this cannot be undone.

Copy Solution: The option is available only for solutions that have been fully completed and sent for training, regardless of the training result. For solutions that have not been submitted for training, the copy option should be present but disabled. What parameters are copied: Name, Solution description, Task type, Target metric, Input data type, Normalization type, Window size, Sliding Shift (for training, for inference), Use raw data for the training, Features to be extracted, Feature Selection, Model Trainable Parameters, Training Stop Options , Target hardware. Settings specified manually by the user in the copied solution: Training dataset, Holdout dataset, Target metric, column for removing, id session column.

Download Training Settings: only for running solutions regardless of training status. only for Enterprise tariff. The downloaded file contains: ID Solution, dataset name (Training Dataset: and Valid Dataset), target name (Target Variable), name of the removed feature (if applicable) (Removing Variable(s)), session name (if applicable) (Session ID), all settings from the Training Pipeline page.

Model Growth Chart: shows the change of the target metric. The idea was to show only the improvement of the metric, but in fact the target metric can go back and forth during training and it confuses the user. That's why the specific logic was implemented in order not to display some of the model versions. Target metric on the chart must always increase(for UP metrics) or always decrease (for DOWN metrics). The logic must be based on the rule that later versions are always better, and sram & flash & modelSize always increase, and target metric increases for UP metric and decreases for DOWN metric.

The "C Library" button for the selected model allows users to download the resulting model and code required for inference on the device. The archive includes the following folders and files:
artifacts: Contains models converted to various formats, along with CLI executables in the infrence_runner directory for making predictions on the desktop.
neuton: Includes header files and compiled libraries for different architectures such as Cortex M0, Cortex M4, Cortex M33, STMicro ISPU, and Microchip-8 series.
neuton-generated: Contains configuration and necessary files to ensure the correct operation of the libraries.
LICENSE: Provides information on the use cases and restrictions for Neuton's intellectual property.
README: Includes detailed instructions for using the libraries effectively.
This setup is designed to help you deploy and integrate the model onto edge devices seamlessly."

To unsubscribe, you'll need to disable billing for your Neuton-related project in Google Cloud Platform (GCP). You can do this by visiting the following link: https://console.cloud.google.com/billing/projects